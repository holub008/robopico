"""
Lightweight classifier class for linear models trained elsewhere

Loads 'npz' files, which contain the model coefficients and
intercepts in sparse (csr) format. This allows very large models
(often several gigabytes in memory uncompressed) to be loaded
reasonably quickly, and makes for feasible memory usage.

kholub note: no need to home roll linear model prediction. replace with sklearn.linear_model.LinearRegression
"""

# Authors:  Iain Marshall <mail@ijmarshall.com>
#           Joel Kuiper <me@joelkuiper.com>
#           Byron Wallace <byron@ccs.neu.edu>

import numpy as np


class LinearClassifier:
    """
    Lightweight classifier
    Does only binary prediction using externally trained data
    """
    def __init__(self, filename):
        '''
        Models are compressed numpy files
        http://docs.scipy.org/doc/numpy/reference/generated/numpy.savez_compressed.html
        with the following keys:
            coef, intercept

            coef: a (1 x n) sparse matrix in csr format (where n
                  is the number of features)
            intercept: single element np.array containing float64

        Coefficients are immediately converted to the dense
        representation to speed up prediction (the .A1 bit returns
        the data contents of the numpy matrix as a numpy array,
        making calculations much quicker)

        Note that coefficients are 'arbitrarily' flipped from 
        positive to negative and vice-versa. The matching process
        will happen to corresponding values generated by any of the
        hashing vectorizers, and hence make the issue go away.
        '''
        with np.load(filename, allow_pickle=True, encoding='latin1') as raw_data:
            self.coef = raw_data["coef"].item().todense().A1
            self.intercept = raw_data["intercept"].item()

    def decision_function(self, X):
        return X.dot(self.coef.T) + self.intercept

    def predict(self, X):
        scores = self.decision_function(X)
        return (scores > 0).astype(np.int)

    def predict_proba(self, X):
        """
        Note! This really only makes sense if the objective 
        for estimating w included a log-loss! Otherwise need 
        to calibrate.
        """

        scores = self.decision_function(X)
        return _sigmoid(scores)


def _sigmoid(z):
    return 1.0 / (1.0 + np.exp(-1.0 * z))
